# Customer Lifetime Value (CLV) Forecaster

## ğŸ¯ Objetivo del Proyecto

Desarrollar un sistema **end-to-end** que calcule y exponga el **Customer Lifetime Value (CLV)** de cada cliente de un e-commerce.  
El entregable incluye:

1. **ETL reproducible** que limpia y consolida las transacciones histÃ³ricas.  
2. **Modelos de CLV** (Pareto/NBD) registrados en MLflow.  
3. **Servicio FastAPI / Docker** con el endpoint `/predict_clv` para integrarse a CRM, ESP o BI.  
4. **Dashboard Streamlit/Plotly** para explorar cohortes y segmentos de valor.

---

## AplicaciÃ³n en la industria

| Ãrea | Uso del CLV | Beneficios concretos |
|------|-------------|----------------------|
| **Marketing de retenciÃ³n** | Priorizar e-mails, SMS o push segÃºn valor futuro | â†“ CAC, â†‘ ROI en canales propios |
| **GestiÃ³n de presupuestos** | Dirigir inversiÃ³n publicitaria a segmentos de mayor retorno | Eficiencia del gasto â†‘ ~15 % |
| **Finanzas** | Proyectar ingresos recurrentes para flujos de caja y valoraciÃ³n | PlanificaciÃ³n mÃ¡s realista que el promedio histÃ³rico |
| **Producto** | Detectar patrones de churn y oportunidades de upsell/cross-sell | Features que elevan la recurrencia |
| **AtenciÃ³n al cliente** | Ajustar SLA y recursos segÃºn valor del cliente | RetenciÃ³n de cuentas de alto valor |


## ğŸš€ Entregables finales  

1. **API REST** (`/predict_clv`) con FastAPI  
2. **Dashboard CLV** interactivo (Plotly/Streamlit)  
3. Pipeline MLOps rastreado en **MLflow** y contenedorizado con **Docker**


## MotivaciÃ³n de negocio

- **Marketing**: identificar segmentos de alto valor y optimizar _Customer
  Acquisition Cost_ (CAC).  
- **Finanzas**: proyectar ingresos futuros y calcular provisiones.  
- **Producto**: priorizar features que eleven retenciÃ³n y compra repetida.


## Dataset

Usamos el **Online Retail II (UCI)**: transacciones de un e-commerce britÃ¡nico
(2009-2011) con: `InvoiceDate`, `CustomerID`, `Quantity`, `Price`,
`Country`.  
El notebook `notebooks/etl_clv.ipynb` descarga y limpia este set, eliminando:

- devoluciones (`Quantity < 0`)
- facturas sin cliente (`CustomerID` nulo)
- pedidos con `UnitPrice â‰¤ 0`

Exporta `data/processed/clv.parquet` comprimido con **Snappy**.

## DescripciÃ³n del dataset â€” *Online Retail II*

**Fuente**  
UCI Machine Learning Repository â†’ *Online Retail II* (transacciÃ³n real de un e-commerce britÃ¡nico)  [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/online%2Bretail%2BII?utm_source=chatgpt.com)

**Volumen**  
â‰ˆ 1,067,000 filas (lÃ­neas de producto) Ã— 8 columnas, cubriendo **01-dic-2009 â†’ 09-dic-2011**. Cada fila registra un artÃ­culo dentro de una factura; una misma factura puede generar varias filas. 

### Esquema de columnas

| Columna        | Tipo sugerido | DescripciÃ³n                                                            |
|----------------|--------------|------------------------------------------------------------------------|
| `Invoice`      | `string`     | CÃ³digo de factura. Prefijo **â€œCâ€** indica devoluciÃ³n.                  |
| `StockCode`    | `string`     | SKU (cÃ³digo del producto).                                             |
| `Description`  | `string`     | Nombre del producto. Incluye caracteres especiales  (ISO-8859-1).      |
| `Quantity`     | `int64`      | Unidades vendidas; **negativo â‡’ devoluciÃ³n**.                          |
| `InvoiceDate`  | `datetime64[ns]` | Fecha y hora de la transacciÃ³n.                                  |
| `UnitPrice`    | `float64`    | Precio unitario (libras esterlinas).                                   |
| `CustomerID`   | `Int64` (nullable) | Identificador de cliente; ~25 % de filas sin ID.            |
| `Country`      | `category`   | PaÃ­s del cliente (38 valores; Reino Unido domina).                     |  [oai_citation:3â€¡Brainly](https://brainly.com/question/33344596?utm_source=chatgpt.com)

### OrganizaciÃ³n y particularidades

1. **Nivel de granularidad** â€“ Cada fila = 1 lÃ­nea de producto; para obtener el ticket completo agrupa por `Invoice`.  
2. **Retornos** â€“ Filas con `Quantity < 0` y `Invoice` con â€œCâ€¦â€ anulan pedidos anteriores.  
3. **Clientes anÃ³nimos** â€“ Ausencia de `CustomerID` impide calcular mÃ©tricas de retenciÃ³n; se recomienda descartarlos o imputar con un placeholder.  
4. **Moneda** â€“ Todos los importes estÃ¡n en **GBP**; convierte a tu divisa si planeas mezclar con otras fuentes.  
5. **TemporizaciÃ³n** â€“ Ventana de casi 2 aÃ±os permite anÃ¡lisis de **cohortes** y modelos de recencia-frecuencia.  
6. **Almacenamiento** â€“ Disponible en `.csv` (~117 MB) y `.xlsx` (dos hojas: *Year 2009-2010*, *Year 2010-2011*). El CSV facilita lecturas en *streaming* y evita dependencias de Excel.  [Preprocessing Large Datasets: Online Retail Data with 500k+ Instances](https://medium.com/data-science/preprocessing-large-datasets-online-retail-data-with-500k-instances-3f24141f511)  
7. **Calidad** â€“ Existen duplicados de lÃ­nea exactos y descripciones vacÃ­as; conviene aplicar `drop_duplicates()` y `fillna('Unknown')`.

### Uso tÃ­pico en proyectos CLV

* **ETL**: leer, filtrar devoluciones, eliminar `UnitPrice â‰¤ 0`, generar columna `Sales = Quantity Ã— UnitPrice`.  
* **RFM**: calcular *Recency*, *Frequency*, *Monetary* por `CustomerID` para alimentar Pareto/NBD.  
* **Cohortes**: agrupar por mes de primera compra (`InvoiceDate.dt.to_period('M')`).  
* **AnÃ¡lisis de producto**: market basket, reglas de asociaciÃ³n por `Invoice`.

> Este dataset es ideal para ejercicios de **customer analytics**, predicciÃ³n de **CLV**, segmentaciÃ³n y detecciÃ³n de churn, ya que refleja compras reales, incluye devoluciones y ofrece una dimensiÃ³n temporal suficiente para modelos de supervivencia.

## Arquitectura de la soluciÃ³n

```text
          +----------+       +-----------+
  CSV  -> |  ETL âœ¨  | ---->  | Parquet   |   ----+
          +----------+       +-----------+       |
                                                 v
                         +-----------------------------------+
                         |  Modelo Pareto/NBD  âœ  CLV table |
                         +-----------------------------------+
                                                |
               +---------------------+          |  MLflow
               |  XGBoost Survival   | ---------+  tracking
               +---------------------+
                        |
                        v
            +-----------------+     Docker / k8s    +--------------+
            | FastAPI server  |  ----------------->  |   React/     |
            | `/predict_clv`  |                     | Streamlit UI |
            +-----------------+                     +--------------+
```

## Estructura de carpetas

```
clv-forecaster/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # zip original de Kaggle
â”‚   â””â”€â”€ processed/        # .parquet limpio
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ mlruns 
â”‚   â”œâ”€â”€ etl_clv.ipynb     # limpieza y feature engineering
â”‚   â””â”€â”€ model_pareto.ipynb
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ bgf.pkl
â”‚   â””â”€â”€ ggf.pkl
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __pycache__/ 
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ main.py       # FastAPI app
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ test_api.py
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
```

## InstalaciÃ³n rÃ¡pida

```bash
git clone https://github.com/luuuisc/clv-forecaster
cd clv-forecaster
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

Requisitos mÃ­nimos
- Python â‰¥ 3.9
- pip â‰¥ 22
- RAM 4 GB (el dataset cabe cÃ³modamente)

## Estructura de carpetas y archivos

| Ruta / archivo | Contenido | Para quÃ© se usa |
|----------------|-----------|-----------------|
| `data/raw/online_retail_II.csv` (âœ— git) | Dataset original descargado de Kaggle | Fuente Ãºnica de verdad. Se mantiene fuera de Git. |
| `data/processed/clv.parquet` | Datos limpios (ventas positivas, tipos correctos) | Input estÃ¡ndar para todos los modelos y dashboards. |
| `data/processed/clv_predictions.parquet` | Tabla final con `frequency`, `recency`, `T`, `monetary`, `clv_6m` | What-if rÃ¡pido y dashboard. |
| `notebooks/etl_clv.ipynb` | CÃ³digo + docs de limpieza **ETL** | Genera `clv.parquet`. |
| `notebooks/model_pareto_nbd.ipynb` | Entrena **BetaGeo** y **GammaGamma**, calcula CLV, registra en MLflow | Prototipo de modelado. |
| `mlruns/` (âœ— git) | Experimentos MLflow | Runs, parÃ¡metros, mÃ©tricas, artefactos. |
| `models/` <br>  â€¢ `bgf.pkl` <br>  â€¢ `ggf.pkl` | Modelos serializados con `joblib` | Cargados por la API para predicciÃ³n on-line. |
| `src/api/main.py` | Servicio **FastAPI** con endpoint `/predict_clv` | Integra los modelos a CRM/ESP/BI. |
| `requirements.txt` | Dependencias fijadas | Reproducibilidad. |
| `README.md` | VisiÃ³n, glosario, pasos, estructura | DocumentaciÃ³n viva. |
| `.gitignore` | Excluye datasets brutos, artefactos MLflow, venv | Repo limpio y ligero. |

### Flujo de trabajo end-to-end

```
CSV bruto  â”€â”€â–¶  etl_clv.ipynb  â”€â”€â–¶  clv.parquet
                               â”‚
                               â–¼
                model_pareto_nbd.ipynb  (RFM + BetaGeo + GammaGamma)
                               â”‚
                               â–¼
                    clv_predictions.parquet
                               â”‚
                               â–¼
                   mlflow run + artefactos
                               â”‚
                               â–¼
            FastAPI /predict_clv  â†’  CRM / ESP / BI
```

## Uso del modelo

#### 1. Clonar y crear venv
```bash
git clone https://github.com/luuuisc/clv-forecaster && cd clv-forecaster
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

#### 2. Colocar CSV bruto (o usar Kaggle API)
```bash
mkdir -p data/raw && cp /tu/ruta/online_retail_II.csv data/raw/
```

#### 3. Ejecutar ETL
```bash
jupyter nbconvert --to notebook --execute notebooks/etl_clv.ipynb
```

#### 4. Entrenar modelo
```bash
jupyter nbconvert --to notebook --execute notebooks/model_pareto_nbd.ipynb
```

#### 5. Servir API
```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000
```

#### 6. EjecuciÃ³n dashboard
```bash
streamlit run dashboards/clv_dashboard.py
```

Swagger disponible en http://localhost:8000/docs.

## ğŸ“Š Dashboard interactivo (Streamlit)

### CÃ³mo ejecutarlo

```bash
# desde la raÃ­z del proyecto
streamlit run dashboards/clv_dashboard.py
# abrirÃ¡ http://localhost:8501
```

Requiere `streamlit` y `plotly`, ya incluidos en `requirements.txt`.

### Componentes del panel Streamlit

| SecciÃ³n                       | Â¿QuÃ© muestra?                                                         | InterpretaciÃ³n clave                                                                                                   | Preguntas que responde                                          |
|-------------------------------|-----------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------|
| **Filtro Â«PaÃ­sÂ»**             | Selector Â«TodosÂ» + 38 paÃ­ses                                          | Actualiza simultÃ¡neamente heatmap, boxplot y mÃ©trica.                                                                  | Â¿CÃ³mo cambian retenciÃ³n y CLV segÃºn paÃ­s o regiÃ³n?              |
| **Filtro Â«Paleta de colorÂ»**  | Opciones: Viridis Â· Blues Â· TealGrn Â· Hot (se puede ampliar)          | Permite al usuario elegir la escala cromÃ¡tica del heatmap para comodidad visual.                                       | â€”                                                               |
| **Heatmap de retenciÃ³n**      | Matriz *Cohorte Ã— Mes* â†’ nÂº clientes activos (escala seleccionada)    | Fila = cohorte de alta; columnas = meses posteriores. Degradado lento = buena retenciÃ³n.                               | Â¿QuÃ© cohorte se comporta mejor? Â¿Hay picos estacionales claros? |
| **Boxplot CLV 6 m**           | DistribuciÃ³n y outliers de `clv_6m`                                   | Caja = IQR; bigotes = rango tÃ­pico; puntos = outliers (valiosos o atÃ­picos).                                           | Â¿CuÃ¡ntos clientes superan Â£X? Â¿Hay concentraciÃ³n de valor?      |
| **MÃ©trica resumen**           | `CLV` medio de la vista actual (con filtros aplicados)                | Sirve de referencia para fijar CAC mÃ¡ximo, evaluar ROI de campaÃ±as, etc.                                               | Â¿CuÃ¡l es el valor medio por cliente en el segmento filtrado?    |


### CÃ³mo sacar insight rÃ¡pidamente
1. Selecciona â€œTodosâ€ â†’ revisa la diagonal principal del heatmap:
    - 60 % la 1Âª columna âœ”ï¸
    - <10 % a los 6 meses âŒ (alerta de churn).
2. Elige un paÃ­s concreto (p.ej. Netherlands).
    - Observa si mantiene o cae mÃ¡s rÃ¡pido vs global.
3. Mira el boxplot:
    - Muchos puntos por encima del upper whisker = oportunidad de campaÃ±a VIP.
    - Caja muy baja = ingresos concentrados en pocos clientes (â€œ80/20â€).

En dos frases:
El dashboard traduce datos transaccionales y predicciones de CLV en visualizaciones accionables para Marketing. Permite comparar retenciÃ³n por cohorte, detectar canales estacionales y evaluar el potencial de ingresos futuro por paÃ­s o segmento.

## ğŸ§ª Â¿CÃ³mo probar el endpoint `/predict_clv`?

### OpciÃ³n A â”€ Swagger UI (recomendado)

1. **Inicia la API**  
   ```bash
   uvicorn src.api.main:app --reload
   ```

2. Abre tu navegador en http://localhost:8000/docs.

    Swagger cargarÃ¡ automÃ¡ticamente todos los endpoints.

3. En la secciÃ³n POST /predict_clv
    - Haz clic y pulsa Try it out.
    - Rellena el JSON de ejemplo:
        ```bash
        {
        "frequency": 3,
        "recency": 120,
        "T": 365,
        "monetary": 40.0
        }
        ```
    - Pulsa Execute.

        En Response body verÃ¡s algo como:
        ```bash
        {
        "clv_6m": 12.48
        }
        ```
        
**InterpretaciÃ³n**

El cliente (3 compras, Ãºltima hace 120 d, 1 aÃ±o de antigÃ¼edad, ticket medio Â£40) se espera que genere Â£12.48 en los prÃ³ximos 6 meses.

### OpciÃ³n B â”€ cURL / Terminal

```bash
curl -X POST http://localhost:8000/predict_clv \
     -H "Content-Type: application/json" \
     -d '{ "frequency": 3, "recency": 120, "T": 365, "monetary": 40.0 }'
```

Respuesta:

```bash
{"clv_6m":12.48}
```

(Puedes sustituir los valores para testear distintos perfiles de cliente.)

### Campos de entrada

| Campo       | Significado                                                                                   |
|-------------|------------------------------------------------------------------------------------------------|
| `frequency` | NÃºmero de compras histÃ³ricas del cliente                                                       |
| `recency`   | DÃ­as transcurridos desde la Ãºltima compra                                                      |
| `T`         | AntigÃ¼edad del cliente en dÃ­as (diferencia entre primera compra y fecha de corte del dataset) |
| `monetary`  | Ticket medio histÃ³rico en GBP (importe medio gastado por compra)                               |

La API valida estos campos con Pydantic; si falta alguno o el tipo es incorrecto devolverÃ¡ 422 Unprocessable Entity.

## TecnologÃ­as y librerÃ­as empleadas

| CategorÃ­a | Paquetes clave | FunciÃ³n |
|-----------|----------------|---------|
| **ManipulaciÃ³n de datos** | `pandas 2.3`, `pyarrow` | Limpieza y Parquet (Snappy). |
| **Modelos CLV** | `lifetimes` (BetaGeoFitter, GammaGammaFitter) | Probabilidad de compra futura y ticket medio. |
| **Experimentos** | `mlflow` | Runs, parÃ¡metros, mÃ©tricas, artefactos. |
| **SerializaciÃ³n** | `joblib` | Guarda modelos para carga rÃ¡pida. |
| **Servicio web** | `fastapi`, `uvicorn`, `pydantic` | API + validaciÃ³n + Swagger. |
| **Dashboard** | `streamlit`, `plotly` | Cohortes y CLV interactivos (prÃ³ximo). |
| **ContenedorizaciÃ³n** | `docker` | Empaquetar API + modelos. |
| **Testing/calidad** | `pytest`, `black`, `flake8` | Calidad y CI (por configurar). |

## Detalle de los modelos

| Modelo | Variables que consume | HiperparÃ¡metros | Salida clave |
|--------|----------------------|-----------------|--------------|
| **BetaGeoFitter** | `frequency`, `recency`, `T` | `penalizer_coef = 0.001` | `pred_purchases_6m` â€“ nÂº esperado de compras en 180 d |
| **GammaGammaFitter** | `frequency`, `monetary` | `penalizer_coef = 0.001` | `exp_avg_sales` â€“ gasto medio esperado por compra |
| **CLV 6 m** | Resultado de ambos modelos | â€” | `clv_6m = pred_purchases_6m Ã— exp_avg_sales` |

## ğŸ—ºï¸ Roadmap Sugerido

Este proyecto estÃ¡ diseÃ±ado para ser construido de manera incremental. A continuaciÃ³n, se presenta una posible secuencia de desarrollo dividida en sprints.

| Sprint | Enfoque Principal             | Entregables Clave                                                              |
| :----- | :---------------------------- | :----------------------------------------------------------------------------- |
| **1**  | **FundaciÃ³n y ETL**           | Estructura del proyecto, pipeline de ETL reproducible (`clv.parquet`).         |
| **2**  | **Primer Modelo y MLOps**     | Modelo baseline (Pareto/NBD) con seguimiento de experimentos en MLflow.        |
| **3**  | **API de PredicciÃ³n**         | Endpoint `/predict_clv` en FastAPI, `Dockerfile` y `docker-compose.yml`.       |
| **4**  | **VisualizaciÃ³n y Modelo Avanzado** | Dashboard interactivo en Streamlit y exploraciÃ³n de un modelo XGBoost Survival. |
| **5**  | **Despliegue a ProducciÃ³n**   | Pipeline de CI/CD para despliegue automÃ¡tico en un servicio cloud (AWS/GCP).  |

## Glosario de siglas y conceptos

| Sigla / tÃ©rmino | Significado | Rol dentro del proyecto |
|-----------------|-------------|-------------------------|
| **ETL** | **E**xtract â€“ **T**ransform â€“ **L**oad | Flujo reproducible que extrae los datos brutos, los limpia y los guarda en Parquet para que todos los pasos posteriores partan de la misma versiÃ³n de los datos. |
| **CLV** | **C**ustomer **L**ifetime **V**alue (Valor de Vida del Cliente) | MÃ©trica clave: ingresos netos que un cliente generarÃ¡ durante toda su relaciÃ³n con la empresa. Es la variable objetivo de nuestros modelos. |
| **Pareto/NBD** | **Pareto / Negative Binomial Distribution** | Modelo estadÃ­stico que, a partir de recencia, frecuencia y edad del cliente, estima la probabilidad de compras futuras y, por extensiÃ³n, el CLV. |
| **XGBoost** | e**X**treme **G**radient **Boost**ing | Algoritmo de Ã¡rboles potenciado por gradiente. En modo â€œsupervivenciaâ€ lo usaremos (opcionalmente) para predecir tiempo hasta la siguiente compra o churn. |
| **MLflow** | *Machine Learning flow* | Plataforma open-source para registrar experimentos, versiones de datos y artefactos de modelos, facilitando reproducibilidad y comparaciÃ³n. |
| **FastAPI** | Framework web asÃ­ncrono en Python | ExpondrÃ¡ el modelo entrenado en un endpoint HTTP (`/predict_clv`) que devuelve el CLV estimado dado un cliente. |
| **Docker** | ContenerizaciÃ³n de aplicaciones | Empaqueta cÃ³digo, dependencias y modelo en una imagen que corre igual en cualquier entorno: local, servidor o nube. |
| **CRM** | **C**ustomer **R**elationship **M**anagement | Sistema donde Marketing/Ventas gestionan contactos. ConsumirÃ¡ nuestro endpoint para mostrar el CLV en tiempo real. |
| **ESP** | **E**-mail **S**ervice **P**rovider | Plataformas de e-mail (SendGrid, Mailchimp). UsarÃ¡n el CLV para personalizar frecuencia, ofertas y segmentaciÃ³n. |
| **BI** | **B**usiness **I**ntelligence | Herramientas de dashboarding (Tableau, Power BI) que podrÃ¡n leer el Parquet o el API para mÃ©tricas agregadas. |
| **Streamlit** | Framework Python para apps web de datos | Construiremos un panel interactivo donde el equipo de negocio explore cohortes y distribuciones de CLV. |
| **Plotly** | LibrerÃ­a de grÃ¡ficas interactivas | GenerarÃ¡ los charts (curvas de retenciÃ³n, boxplots, etc.) dentro del dashboard de Streamlit. |

## Contribuciones

Las pull-requests son bienvenidas. 

Antes de proponer cambios:
1. Crea un issue con descripciÃ³n concisa.
2. Sigue el estilo de commit feat|fix|docs(scope): mensaje.
3. Verifica que pytest y flake8 pasen localmente.

## Licencia

This project is licensed under the MIT License.
