# Customer Lifetime Value (CLV) Forecaster

## ğŸ¯ Objetivo del Proyecto

Desarrollar un sistema **end-to-end** que calcule y exponga el **Customer Lifetime Value (CLV)** de cada cliente de un e-commerce.  
El entregable incluye:

1. **ETL reproducible** que limpia y consolida las transacciones histÃ³ricas.  
2. **Modelos de CLV** (Pareto/NBD + XGBoost de supervivencia opcional) registrados en MLflow.  
3. **Servicio FastAPI / Docker** con el endpoint `/predict_clv` para integrarse a CRM, ESP o BI.  
4. **Dashboard Streamlit/Plotly** para explorar cohortes y segmentos de valor.

---

## AplicaciÃ³n en la industria

| Ãrea | Uso del CLV | Beneficios concretos |
|------|-------------|----------------------|
| **Marketing de retenciÃ³n** | Priorizar e-mails, SMS o push segÃºn valor futuro | â†“ CAC, â†‘ ROI en canales propios |
| **GestiÃ³n de presupuestos** | Dirigir inversiÃ³n publicitaria a segmentos de mayor retorno | Eficiencia del gasto â†‘ ~15 % |
| **Finanzas** | Proyectar ingresos recurrentes para flujos de caja y valoraciÃ³n | PlanificaciÃ³n mÃ¡s realista que el promedio histÃ³rico |
| **Producto** | Detectar patrones de churn y oportunidades de upsell/cross-sell | Features que elevan la recurrencia |
| **AtenciÃ³n al cliente** | Ajustar SLA y recursos segÃºn valor del cliente | RetenciÃ³n de cuentas de alto valor |


## ğŸš€ Entregables finales  

1. **API REST** (`/predict_clv`) con FastAPI  
2. **Dashboard CLV** interactivo (Plotly/Streamlit)  
3. Pipeline MLOps rastreado en **MLflow** y contenedorizado con **Docker**


## MotivaciÃ³n de negocio

- **Marketing**: identificar segmentos de alto valor y optimizar _Customer
  Acquisition Cost_ (CAC).  
- **Finanzas**: proyectar ingresos futuros y calcular provisiones.  
- **Producto**: priorizar features que eleven retenciÃ³n y compra repetida.


## Dataset

Usamos el **Online Retail II (UCI)**: transacciones de un e-commerce britÃ¡nico
(2009-2011) con: `InvoiceDate`, `CustomerID`, `Quantity`, `Price`,
`Country`.  
El notebook `notebooks/etl_clv.ipynb` descarga y limpia este set, eliminando:

- devoluciones (`Quantity < 0`)
- facturas sin cliente (`CustomerID` nulo)
- pedidos con `UnitPrice â‰¤ 0`

Exporta `data/processed/clv.parquet` comprimido con **Snappy**.

## DescripciÃ³n del dataset â€” *Online Retail II*

**Fuente**  
UCI Machine Learning Repository â†’ *Online Retail II* (transacciÃ³n real de un e-commerce britÃ¡nico)  [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/online%2Bretail%2BII?utm_source=chatgpt.com)

**Volumen**  
â‰ˆ 1,067,000 filas (lÃ­neas de producto) Ã— 8 columnas, cubriendo **01-dic-2009 â†’ 09-dic-2011**. Cada fila registra un artÃ­culo dentro de una factura; una misma factura puede generar varias filas.  [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/online%2Bretail%2BII?utm_source=chatgpt.com) 
[Kaggle](https://www.kaggle.com/datasets/mathchi/online-retail-ii-data-set-from-ml-repository?utm_source=chatgpt.com)

### Esquema de columnas

| Columna        | Tipo sugerido | DescripciÃ³n                                                            |
|----------------|--------------|------------------------------------------------------------------------|
| `Invoice`      | `string`     | CÃ³digo de factura. Prefijo **â€œCâ€** indica devoluciÃ³n.                  |
| `StockCode`    | `string`     | SKU (cÃ³digo del producto).                                             |
| `Description`  | `string`     | Nombre del producto. Incluye caracteres especiales  (ISO-8859-1).      |
| `Quantity`     | `int64`      | Unidades vendidas; **negativo â‡’ devoluciÃ³n**.                          |
| `InvoiceDate`  | `datetime64[ns]` | Fecha y hora de la transacciÃ³n.                                  |
| `UnitPrice`    | `float64`    | Precio unitario (libras esterlinas).                                   |
| `CustomerID`   | `Int64` (nullable) | Identificador de cliente; ~25 % de filas sin ID.            |
| `Country`      | `category`   | PaÃ­s del cliente (38 valores; Reino Unido domina).                     |  [oai_citation:3â€¡Brainly](https://brainly.com/question/33344596?utm_source=chatgpt.com)

### OrganizaciÃ³n y particularidades

1. **Nivel de granularidad** â€“ Cada fila = 1 lÃ­nea de producto; para obtener el ticket completo agrupa por `Invoice`.  
2. **Retornos** â€“ Filas con `Quantity < 0` y `Invoice` con â€œCâ€¦â€ anulan pedidos anteriores.  
3. **Clientes anÃ³nimos** â€“ Ausencia de `CustomerID` impide calcular mÃ©tricas de retenciÃ³n; se recomienda descartarlos o imputar con un placeholder.  
4. **Moneda** â€“ Todos los importes estÃ¡n en **GBP**; convierte a tu divisa si planeas mezclar con otras fuentes.  
5. **TemporizaciÃ³n** â€“ Ventana de casi 2 aÃ±os permite anÃ¡lisis de **cohortes** y modelos de recencia-frecuencia.  
6. **Almacenamiento** â€“ Disponible en `.csv` (~117 MB) y `.xlsx` (dos hojas: *Year 2009-2010*, *Year 2010-2011*). El CSV facilita lecturas en *streaming* y evita dependencias de Excel.  [oai_citation:4â€¡Medium](https://medium.com/data-science/preprocessing-large-datasets-online-retail-data-with-500k-instances-3f24141f511?utm_source=chatgpt.com)  
7. **Calidad** â€“ Existen duplicados de lÃ­nea exactos y descripciones vacÃ­as; conviene aplicar `drop_duplicates()` y `fillna('Unknown')`.

### Uso tÃ­pico en proyectos CLV

* **ETL**: leer, filtrar devoluciones, eliminar `UnitPrice â‰¤ 0`, generar columna `Sales = Quantity Ã— UnitPrice`.  
* **RFM**: calcular *Recency*, *Frequency*, *Monetary* por `CustomerID` para alimentar Pareto/NBD.  
* **Cohortes**: agrupar por mes de primera compra (`InvoiceDate.dt.to_period('M')`).  
* **AnÃ¡lisis de producto**: market basket, reglas de asociaciÃ³n por `Invoice`.

> Este dataset es ideal para ejercicios de **customer analytics**, predicciÃ³n de **CLV**, segmentaciÃ³n y detecciÃ³n de churn, ya que refleja compras reales, incluye devoluciones y ofrece una dimensiÃ³n temporal suficiente para modelos de supervivencia.

## Arquitectura de la soluciÃ³n

```text
          +----------+       +-----------+
  CSV  -> |  ETL âœ¨  | ---->  | Parquet   |   ----+
          +----------+       +-----------+       |
                                                 v
                         +-----------------------------------+
                         |  Modelo Pareto/NBD  âœ  CLV table |
                         +-----------------------------------+
                                                |
               +---------------------+          |  MLflow
               |  XGBoost Survival   | ---------+  tracking
               +---------------------+
                        |
                        v
            +-----------------+     Docker / k8s    +--------------+
            | FastAPI server  |  ----------------->  |   React/     |
            | `/predict_clv`  |                     | Streamlit UI |
            +-----------------+                     +--------------+
```

## Estructura de carpetas

```
clv-forecaster/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # zip original de Kaggle
â”‚   â””â”€â”€ processed/        # .parquet limpio
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ etl_clv.ipynb     # limpieza y feature engineering
â”‚   â””â”€â”€ model_pareto.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ load.py
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pareto_nbd.py
â”‚   â”‚   â””â”€â”€ xgb_survival.py
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ main.py       # FastAPI app
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml        # lint + tests + build
```


## InstalaciÃ³n rÃ¡pida

```bash
git clone https://github.com/<tu-user>/clv-forecaster.git
cd clv-forecaster
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

Requisitos mÃ­nimos
- Python â‰¥ 3.9
- pip â‰¥ 22
- RAM 4 GB (el dataset cabe cÃ³modamente)

## Uso rÃ¡pido

1.	ETL

    ```bash
    jupyter notebook notebooks/etl_clv.ipynb
    ```

2. Entrenamiento + tracking

    ```bash
    python -m src.models.pareto_nbd train
    mlflow ui
    ```

3. API local

    ```bash
    uvicorn src.api.main:app --reload
    ```

4. Dashboard

    ```bash
    streamlit run dashboards/clv_dashboard.py
    ```

## Principales dependencias

| CategorÃ­a                 | Paquete(s)                         | PropÃ³sito Principal                                                      |
| :------------------------ | :--------------------------------- | :----------------------------------------------------------------------- |
| **AnÃ¡lisis de Datos**     | `pandas`, `pyarrow`                | ManipulaciÃ³n de datos y lectura/escritura eficiente en formato Parquet.    |
| **Modelado CLV**          | `lifetimes`, `xgboost`             | ImplementaciÃ³n de modelos probabilÃ­sticos (Pareto/NBD) y de supervivencia. |
| **MLOps**                 | `mlflow`                           | Seguimiento de experimentos, versionado de modelos y registro de mÃ©tricas. |
| **API & Backend**         | `fastapi`, `uvicorn`               | CreaciÃ³n de una API REST de alto rendimiento para servir predicciones.   |
| **VisualizaciÃ³n**         | `streamlit`, `plotly`              | Desarrollo de dashboards interactivos para explorar resultados y cohortes. |
| **Testing & Calidad**     | `pytest`, `hypothesis`             | Pruebas unitarias, de integraciÃ³n y basadas en propiedades.              |
| **ContenerizaciÃ³n**       | `docker`, `docker-compose`         | Empaquetado de la aplicaciÃ³n y sus dependencias para un despliegue aislado y reproducible. |

## Buenas prÃ¡cticas incluidas
- Copy-on-Write en Pandas 2.3 para memoria eficiente.
- Tipado con type hints y mypy.
- Pre-commit hooks: black, flake8, isort.
- Tests de rendimiento (pytest-benchmark) en modelos.
- Continuous Integration (GitHub Actions) â†’ lint + tests + build Docker.

## ğŸ—ºï¸ Roadmap Sugerido

Este proyecto estÃ¡ diseÃ±ado para ser construido de manera incremental. A continuaciÃ³n, se presenta una posible secuencia de desarrollo dividida en sprints.

| Sprint | Enfoque Principal             | Entregables Clave                                                              |
| :----- | :---------------------------- | :----------------------------------------------------------------------------- |
| **1**  | **FundaciÃ³n y ETL**           | Estructura del proyecto, pipeline de ETL reproducible (`clv.parquet`).         |
| **2**  | **Primer Modelo y MLOps**     | Modelo baseline (Pareto/NBD) con seguimiento de experimentos en MLflow.        |
| **3**  | **API de PredicciÃ³n**         | Endpoint `/predict_clv` en FastAPI, `Dockerfile` y `docker-compose.yml`.       |
| **4**  | **VisualizaciÃ³n y Modelo Avanzado** | Dashboard interactivo en Streamlit y exploraciÃ³n de un modelo XGBoost Survival. |
| **5**  | **Despliegue a ProducciÃ³n**   | Pipeline de CI/CD para despliegue automÃ¡tico en un servicio cloud (AWS/GCP).  |

## Glosario de siglas y conceptos

| Sigla / tÃ©rmino | Significado | Rol dentro del proyecto |
|-----------------|-------------|-------------------------|
| **ETL** | **E**xtract â€“ **T**ransform â€“ **L**oad | Flujo reproducible que extrae los datos brutos, los limpia y los guarda en Parquet para que todos los pasos posteriores partan de la misma versiÃ³n de los datos. |
| **CLV** | **C**ustomer **L**ifetime **V**alue (Valor de Vida del Cliente) | MÃ©trica clave: ingresos netos que un cliente generarÃ¡ durante toda su relaciÃ³n con la empresa. Es la variable objetivo de nuestros modelos. |
| **Pareto/NBD** | **Pareto / Negative Binomial Distribution** | Modelo estadÃ­stico que, a partir de recencia, frecuencia y edad del cliente, estima la probabilidad de compras futuras y, por extensiÃ³n, el CLV. |
| **XGBoost** | e**X**treme **G**radient **Boost**ing | Algoritmo de Ã¡rboles potenciado por gradiente. En modo â€œsupervivenciaâ€ lo usaremos (opcionalmente) para predecir tiempo hasta la siguiente compra o churn. |
| **MLflow** | *Machine Learning flow* | Plataforma open-source para registrar experimentos, versiones de datos y artefactos de modelos, facilitando reproducibilidad y comparaciÃ³n. |
| **FastAPI** | Framework web asÃ­ncrono en Python | ExpondrÃ¡ el modelo entrenado en un endpoint HTTP (`/predict_clv`) que devuelve el CLV estimado dado un cliente. |
| **Docker** | ContenerizaciÃ³n de aplicaciones | Empaqueta cÃ³digo, dependencias y modelo en una imagen que corre igual en cualquier entorno: local, servidor o nube. |
| **CRM** | **C**ustomer **R**elationship **M**anagement | Sistema donde Marketing/Ventas gestionan contactos. ConsumirÃ¡ nuestro endpoint para mostrar el CLV en tiempo real. |
| **ESP** | **E**-mail **S**ervice **P**rovider | Plataformas de e-mail (SendGrid, Mailchimp). UsarÃ¡n el CLV para personalizar frecuencia, ofertas y segmentaciÃ³n. |
| **BI** | **B**usiness **I**ntelligence | Herramientas de dashboarding (Tableau, Power BI) que podrÃ¡n leer el Parquet o el API para mÃ©tricas agregadas. |
| **Streamlit** | Framework Python para apps web de datos | Construiremos un panel interactivo donde el equipo de negocio explore cohortes y distribuciones de CLV. |
| **Plotly** | LibrerÃ­a de grÃ¡ficas interactivas | GenerarÃ¡ los charts (curvas de retenciÃ³n, boxplots, etc.) dentro del dashboard de Streamlit. |

**Idea global**  
1. **ETL** prepara los datos â†’ 2. **Modelos** (Pareto/NBD y/o XGBoost) calculan CLV â†’ 3. **MLflow** registra todo â†’ 4. **FastAPI + Docker** sirven el modelo a otros sistemas (**CRM**, **ESP**, **BI**) â†’ 5. **Streamlit/Plotly** ofrecen una interfaz visual para analistas y marketers.

## Contribuciones

Las pull-requests son bienvenidas. Antes de proponer cambios:
	1.	Crea un issue con descripciÃ³n concisa.
	2.	Sigue el estilo de commit feat|fix|docs(scope): mensaje.
	3.	Verifica que pytest y flake8 pasen localmente.

## Licencia

This project is licensed under the MIT License.

## Referencias clave
- Fader, Sarmi & Hardie â€“ Customer-Base Analysis in a Discrete-Time Framework.
- Wes McKinney â€“ Python for Data Analysis (3.Âª ed.).
- Sitio oficial de Pandas 2.3 â€“ guÃ­a Copy-on-Write.
- Blog B. Coussement â€“ â€œCLV Models with Pareto/NBDâ€.
